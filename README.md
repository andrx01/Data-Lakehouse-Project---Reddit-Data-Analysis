## ğŸ“Œ VisÃ£o Geral

Este projeto implementa uma arquitetura **Data Lakehouse** para coletar, processar e analisar dados do Reddit relacionados a **AnÃ¡lise de Dados**, **CiÃªncia de Dados**, **Engenharia de Dados**, **Machine Learning** e temas relacionados. O pipeline Ã© dividido em trÃªs camadas: **Bronze**, **Silver** e **Gold**, garantindo um fluxo de dados limpo, estruturado e pronto para visualizaÃ§Ã£o.

---

## ğŸ—ï¸ Arquitetura

* **Bronze:** Coleta de dados brutos via API do Reddit.
* **Silver:** Limpeza, normalizaÃ§Ã£o e classificaÃ§Ã£o de relevÃ¢ncia dos posts.
* **Gold:** AgregaÃ§Ãµes, mÃ©tricas e visualizaÃ§Ãµes finais.

ğŸ“‚ Estrutura de pastas:

```
data_lakehouse_project/
â”‚â”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Dados brutos
â”‚   â”œâ”€â”€ silver/       # Dados limpos
â”‚   â””â”€â”€ gold/         # MÃ©tricas e grÃ¡ficos finais
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/    # Scripts de ingestÃ£o (Bronze)
â”‚   â”œâ”€â”€ processing/   # Scripts de transformaÃ§Ã£o (Silver)
â”‚   â””â”€â”€ analytics/    # Scripts de anÃ¡lise e grÃ¡ficos (Gold)
â”‚â”€â”€ pipeline.py        # Pipeline completo
â”‚â”€â”€ requirements.txt   # DependÃªncias do projeto
```

---

## ğŸš€ ExecuÃ§Ã£o do Pipeline Completo

Para executar todo o processo automaticamente:

```bash
python src/pipeline.py
```

ğŸ”¹ Isso farÃ¡:

1. Coleta de posts do Reddit (Bronze)
2. TransformaÃ§Ã£o e limpeza dos dados (Silver)
3. GeraÃ§Ã£o de mÃ©tricas e grÃ¡ficos (Gold)

Os resultados finais estarÃ£o em:

```
data/gold/
```

---

## ğŸ“Š VisualizaÃ§Ãµes Geradas

* **Wordcloud** â€“ Principais termos
* **Top Bigramas** â€“ CombinaÃ§Ãµes de palavras mais frequentes
* **Palavras mais frequentes** â€“ AnÃ¡lise de frequÃªncia
* **Posts ao longo do tempo** â€“ EvoluÃ§Ã£o temporal
* **Posts por subreddit** â€“ DistribuiÃ§Ã£o de publicaÃ§Ãµes
* **Engajamento mÃ©dio** â€“ Score mÃ©dio por subreddit
* **Top autores e posts** â€“ UsuÃ¡rios com maior contribuiÃ§Ã£o

Exemplo de grÃ¡ficos:

* ![Wordcloud](data/gold/wordcloud.png)
* ![Top Bigramas](data/gold/bigrams.png)
* ![Posts por Subreddit](data/gold/posts_by_subreddit.png)

---

## âš™ï¸ ConfiguraÃ§Ã£o do Projeto

1. **Instalar dependÃªncias:**

```bash
pip install -r requirements.txt
```

2. **Definir credenciais do Reddit:**

* Editar o arquivo `configs/config.yaml` com:

```yaml
reddit:
  client_id: "SEU_CLIENT_ID"
  client_secret: "SEU_SECRET"
  user_agent: "data_lakehouse_app"
```

---

## ğŸ§  Tecnologias Utilizadas

* Python 3.11+
* PRAW (Reddit API)
* Pandas / NumPy
* Scikit-learn (ClassificaÃ§Ã£o)
* Seaborn / Matplotlib / Wordcloud

